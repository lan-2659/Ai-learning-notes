{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14e7b9b",
   "metadata": {},
   "source": [
    "使用神经网络训练和验证数据集：\n",
    "\n",
    "1. 数据准备\n",
    "   - 创建/加载数据集\n",
    "     - 使用适当的方法创建或加载数据集（例如，使用`torchvision.datasets`或自定义数据集）。\n",
    "     - 将数据集划分为训练集、验证集和测试集。\n",
    "   - 创建数据加载器（`DataLoader`）以便进行批量训练。\n",
    "2. 创建模型\n",
    "   - 定义一个神经网络模型，通常继承`nn.Module`。\n",
    "   - 在构造函数中定义网络层（如全连接层、卷积层等）。\n",
    "   - 在`forward`方法中定义前向传播。\n",
    "3. 定义损失函数和优化器\n",
    "   - 选择适合任务的损失函数（如分类任务使用交叉熵损失`nn.CrossEntropyLoss`，回归任务使用均方误差`nn.MSELoss`）。\n",
    "   - 选择一个优化器（如`optim.SGD`或`optim.Adam`）并设置学习率。\n",
    "4. 训练模型\n",
    "   - 循环多个epoch（训练周期）。\n",
    "   - 在每个epoch中，遍历训练数据加载器，每次获取一个批次的数据。\n",
    "   - 将数据输入模型得到输出，计算损失。\n",
    "   - 清零梯度，反向传播，优化器更新参数。\n",
    "   - 可选：记录训练损失和准确率。\n",
    "5. 验证模型\n",
    "   - 在每个epoch结束后，使用验证集评估模型。\n",
    "   - 将模型设置为评估模式（`model.eval()`），关闭梯度计算（`torch.no_grad()`）。\n",
    "   - 遍历验证数据加载器，计算验证损失和准确率。\n",
    "   - 根据验证结果调整超参数或进行早停（early stopping）等操作。\n",
    "6. 保存模型\n",
    "   - 使用`torch.save`保存模型的状态字典（`state_dict`）或整个模型。\n",
    "   - 通常保存验证性能最好的模型。\n",
    "7. 模型预测\n",
    "   - 加载保存的模型。\n",
    "   - 对新数据（单一样本或批次）进行预测，注意数据预处理和转换为张量。\n",
    "   - 将模型输出转换为预测标签（如分类问题使用softmax和argmax）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684945b1",
   "metadata": {},
   "source": [
    "1.使用全连接网络训练和验证MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b3d8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.18691670894622803, acc: 0.85915\n",
      "Epoch: 10, Loss: 0.006430135574191809, acc: 0.9986666666666667\n",
      "Epoch: 20, Loss: 0.011783843860030174, acc: 0.9969333333333333\n",
      "Epoch: 30, Loss: 9.147380478680134e-05, acc: 1.0\n",
      "Epoch: 40, Loss: 4.7696405090391636e-05, acc: 1.0\n",
      "Epoch: 50, Loss: 3.165101952617988e-05, acc: 1.0\n",
      "Epoch: 60, Loss: 3.136577652185224e-05, acc: 1.0\n",
      "Epoch: 70, Loss: 1.6336618500645272e-05, acc: 1.0\n",
      "Epoch: 80, Loss: 1.6351716112694703e-05, acc: 1.0\n",
      "Epoch: 90, Loss: 9.618052899895702e-06, acc: 1.0\n",
      "loss: 0.12755970656871796 acc: 0.9816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 数据准备:加载数据集（MNIST），返回训练/验证数据集加载器\n",
    "def build_dataLoader(*, train=False, test=False):\n",
    "\n",
    "    trainLoader, testLoader = None, None\n",
    "\n",
    "    if train:\n",
    "\n",
    "        trainDataset = datasets.MNIST(\n",
    "            root=\"./图片资料\",\n",
    "            train=True,\n",
    "            transform=transforms.ToTensor(),\n",
    "            download=True,\n",
    "        )\n",
    "\n",
    "        trainLoader = DataLoader(\n",
    "            trainDataset,\n",
    "            batch_size=len(trainDataset) // 20,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    if test:\n",
    "\n",
    "        testDataset = datasets.MNIST(\n",
    "            root=\"./图片资料\",\n",
    "            train=False,\n",
    "            transform=transforms.ToTensor(),\n",
    "            download=True,\n",
    "        )\n",
    "\n",
    "        testLoader = DataLoader(\n",
    "            testDataset,\n",
    "            batch_size=len(testDataset) // 10,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    if trainLoader is not None and testLoader is not None:\n",
    "        return trainLoader, testLoader\n",
    "    elif trainLoader is not None and testLoader is None:\n",
    "        return trainLoader\n",
    "    elif testLoader is not None and trainLoader is None:\n",
    "        return testLoader\n",
    "\n",
    "\n",
    "# 构建模型结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.BN1 = nn.BatchNorm1d(256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.BN2 = nn.BatchNorm1d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.BN1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.BN2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train(model, train_loader, lr, epochs):\n",
    "    model.train()\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        crrect = 0\n",
    "        for x, y in train_loader:\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            crrect += (torch.max(y_pred, dim=1)[1].eq(y)).sum().item()\n",
    "\n",
    "        accuracy = crrect / len(train_loader.dataset)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss: {loss.item()}, acc: {accuracy}\")\n",
    "\n",
    "\n",
    "# 验证模型\n",
    "def eval(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        crrect = 0\n",
    "        for x, y in test_loader:\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            crrect += (torch.max(y_pred, dim=1)[1] == y).sum().item()\n",
    "\n",
    "        accuracy = crrect / len(test_loader.dataset)\n",
    "        print(f\"loss: {loss.item()} acc: {accuracy}\")\n",
    "\n",
    "\n",
    "# 保存模型\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "def load_model(path):\n",
    "    model = Net(1 * 28 * 28, 10)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "\n",
    "# 预测\n",
    "def predict(model, test_path):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((28, 28))])\n",
    "\n",
    "    img = Image.open(test_path).convert('L')\n",
    "    img = transform(img).unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(img)\n",
    "        pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        print(f\"预测分类：{pred.item()}\")\n",
    "\n",
    "\n",
    "train_loader, test_loader = build_dataLoader(train=True, test=True)\n",
    "model = Net(784, 10)\n",
    "train(model, train_loader, 0.01, 100)\n",
    "eval(model, test_loader)\n",
    "save_model(model, \"./model/mnist_model.pth\")\n",
    "\n",
    "# model = load_model(\"./model/mnist_model.pth\")\n",
    "# predict(model, r\"图片资料\\3.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2ca9c",
   "metadata": {},
   "source": [
    "2.使用全连接网络训练和验证CIFAR10数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "981a07eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.9758 Acc: 0.1983\n",
      "Epoch: 2, Loss: 1.9311 Acc: 0.2901\n",
      "Epoch: 3, Loss: 1.8783 Acc: 0.3156\n",
      "Epoch: 4, Loss: 1.9075 Acc: 0.3257\n",
      "Epoch: 5, Loss: 1.8573 Acc: 0.3298\n",
      "Epoch: 6, Loss: 1.8757 Acc: 0.3330\n",
      "Epoch: 7, Loss: 1.8739 Acc: 0.3341\n",
      "Epoch: 8, Loss: 1.8415 Acc: 0.3342\n",
      "Epoch: 9, Loss: 1.8559 Acc: 0.3359\n",
      "Epoch: 10, Loss: 1.7869 Acc: 0.3388\n",
      "Epoch: 11, Loss: 1.8374 Acc: 0.3352\n",
      "Epoch: 12, Loss: 1.8598 Acc: 0.3353\n",
      "Epoch: 13, Loss: 1.8270 Acc: 0.3382\n",
      "Epoch: 14, Loss: 1.8251 Acc: 0.3401\n",
      "Epoch: 15, Loss: 1.8432 Acc: 0.3398\n",
      "Epoch: 16, Loss: 1.8054 Acc: 0.3382\n",
      "Epoch: 17, Loss: 1.8283 Acc: 0.3374\n",
      "Epoch: 18, Loss: 1.8404 Acc: 0.3409\n",
      "Epoch: 19, Loss: 1.8199 Acc: 0.3412\n",
      "Epoch: 20, Loss: 1.8521 Acc: 0.3398\n",
      "Epoch: 21, Loss: 1.8676 Acc: 0.3422\n",
      "Epoch: 22, Loss: 1.8592 Acc: 0.3434\n",
      "Epoch: 23, Loss: 1.8541 Acc: 0.3450\n",
      "Epoch: 24, Loss: 1.8064 Acc: 0.3424\n",
      "Epoch: 25, Loss: 1.8233 Acc: 0.3443\n",
      "Epoch: 26, Loss: 1.8611 Acc: 0.3458\n",
      "Epoch: 27, Loss: 1.8341 Acc: 0.3462\n",
      "Epoch: 28, Loss: 1.8146 Acc: 0.3447\n",
      "Epoch: 29, Loss: 1.8236 Acc: 0.3462\n",
      "Epoch: 30, Loss: 1.8405 Acc: 0.3461\n",
      "Epoch: 31, Loss: 1.8087 Acc: 0.3441\n",
      "Epoch: 32, Loss: 1.7851 Acc: 0.3481\n",
      "Epoch: 33, Loss: 1.8004 Acc: 0.3487\n",
      "Epoch: 34, Loss: 1.8305 Acc: 0.3516\n",
      "Epoch: 35, Loss: 1.7837 Acc: 0.3501\n",
      "Epoch: 36, Loss: 1.7971 Acc: 0.3499\n",
      "Epoch: 37, Loss: 1.8390 Acc: 0.3501\n",
      "Epoch: 38, Loss: 1.8316 Acc: 0.3458\n",
      "Epoch: 39, Loss: 1.8208 Acc: 0.3458\n",
      "Epoch: 40, Loss: 1.7987 Acc: 0.3482\n",
      "Epoch: 41, Loss: 1.8095 Acc: 0.3463\n",
      "Epoch: 42, Loss: 1.8184 Acc: 0.3513\n",
      "Epoch: 43, Loss: 1.7897 Acc: 0.3521\n",
      "Epoch: 44, Loss: 1.8010 Acc: 0.3497\n",
      "Epoch: 45, Loss: 1.8074 Acc: 0.3490\n",
      "Epoch: 46, Loss: 1.8076 Acc: 0.3511\n",
      "Epoch: 47, Loss: 1.8028 Acc: 0.3512\n",
      "Epoch: 48, Loss: 1.8082 Acc: 0.3496\n",
      "Epoch: 49, Loss: 1.7897 Acc: 0.3534\n",
      "Epoch: 50, Loss: 1.8477 Acc: 0.3479\n",
      "测试集验证结果：\n",
      " Loss: 1.7295807600021362 Acc: 0.3888\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 数据准备，返回训练集数据加载器和测试集数据加载器\n",
    "def build_dataLoader():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))      # 归一化\n",
    "    ])\n",
    "    \n",
    "    trainDataset = datasets.CIFAR10(\n",
    "        root=\"./图片资料\",\n",
    "        train=True,\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    testDataset = datasets.CIFAR10(\n",
    "        root=\"./图片资料\",\n",
    "        train=False,\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    trainLoader = DataLoader(\n",
    "        dataset=trainDataset,\n",
    "        batch_size=len(trainDataset)//20,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    testLoader = DataLoader(\n",
    "        dataset=testDataset,\n",
    "        batch_size=len(testDataset)//10,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    return trainLoader, testLoader\n",
    "\n",
    "\n",
    "\n",
    "# 构建网络结构\n",
    "class CIFAR10Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(32*32*3, 1024)\n",
    "        # self.BN1 = nn.BatchNorm1d(1024)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        # self.BN2 = nn.BatchNorm1d(512)\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        # self.BN3 = nn.BatchNorm1d(256)\n",
    "        self.tanh3 = nn.Tanh()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc4 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = self.BN1(x)\n",
    "        x = self.tanh1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # x = self.BN2(x)\n",
    "        x = self.tanh2(x)\n",
    "        x = self.relu2(x)\n",
    "        # x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        # x = self.BN3(x)\n",
    "        x = self.tanh3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# 训练\n",
    "def train(model, train_loader, test_loader, lr, epochs):\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        crrect_num = 0\n",
    "        for data in train_loader:\n",
    "            x, y = data\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            crrect_num += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "        acc_list.append(crrect_num / len(train_loader.dataset))\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item():0.4f} Acc: {crrect_num / len(train_loader.dataset):0.4f}\")\n",
    "\n",
    "        if epoch > 20 and acc_list[-1] - acc_list[-2] < 0.01 and loss_list[-2] - loss_list[-1] < 0.001:\n",
    "            patience += 1\n",
    "            if patience > 5:\n",
    "                print('模型训练连续5次没有进步，结束训练')\n",
    "                break\n",
    "        else:\n",
    "            patience = 0\n",
    "            \n",
    "\n",
    "\n",
    "# 测试\n",
    "def eval(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        crrect_num = 0\n",
    "        \n",
    "        for data in test_loader:\n",
    "            x, y = data\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            crrect_num += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        print(f\"测试集验证结果：\\n Loss: {loss.item()} Acc: {crrect_num / len(test_loader.dataset)}\")\n",
    "\n",
    "\n",
    "# 保存模型\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "def load_model(path):\n",
    "    model = CIFAR10Net()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "\n",
    "# 预测\n",
    "def predict(model, path):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))      # 归一化\n",
    "        ])\n",
    "\n",
    "        img = Image.open(path)\n",
    "        img = transform(img)\n",
    "        img = img.view(-1, 3 * 32 * 32)\n",
    "\n",
    "        output = model(img)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        print(pred.item())\n",
    "\n",
    "trainLoader, testLoader = build_dataLoader()\n",
    "model = CIFAR10Net()\n",
    "train(model, trainLoader, testLoader, 0.01, 50)\n",
    "eval(model, testLoader)\n",
    "save_model(model, 'model/cifar10_model.pth')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
